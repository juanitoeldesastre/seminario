{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJri_-NOBeCm"
      },
      "outputs": [],
      "source": [
        "# === BLOQUE 1: CREACIÓN DE ARCHIVOS CSV CON DATOS ALEATORIOS ===\n",
        "\n",
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Fijamos una semilla para garantizar la reproducibilidad de los datos\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generamos datos aleatorios para las ventas\n",
        "ventas_data = {\n",
        "    'ProductoID': np.random.randint(1000, 2000, 20),  # IDs de productos aleatorios\n",
        "    'UsuarioID': np.random.randint(1, 100, 20),       # IDs de usuarios aleatorios\n",
        "    'CantidadVendida': np.random.randint(1, 10, 20),  # Cantidad de productos vendidos\n",
        "    'FechaVenta': pd.date_range(start='2023-01-01', periods=20, freq='D').strftime('%Y-%m-%d')\n",
        "}\n",
        "\n",
        "# Creamos un DataFrame para los datos de ventas\n",
        "ventas_df = pd.DataFrame(ventas_data)\n",
        "\n",
        "# Guardamos el DataFrame como un archivo CSV\n",
        "ventas_df.to_csv('ventas.csv', index=False)\n",
        "\n",
        "# Generamos datos aleatorios para el comportamiento de usuario\n",
        "usuarios_data = {\n",
        "    'UsuarioID': np.random.randint(1, 100, 20),        # IDs de usuarios aleatorios\n",
        "    'TiempoEnSitio': np.random.uniform(1, 50, 20),     # Tiempo en el sitio web (minutos)\n",
        "    'PaginasVistas': np.random.randint(1, 20, 20),     # Cantidad de páginas vistas\n",
        "    'ProductosVistos': np.random.randint(1, 10, 20)    # Cantidad de productos vistos\n",
        "}\n",
        "\n",
        "# Creamos un DataFrame para los datos de usuarios\n",
        "usuarios_df = pd.DataFrame(usuarios_data)\n",
        "\n",
        "# Guardamos el DataFrame como un archivo CSV\n",
        "usuarios_df.to_csv('usuarios.csv', index=False)\n",
        "\n",
        "print(\"Archivos CSV 'ventas.csv' y 'usuarios.csv' creados con éxito.\")\n",
        "\n",
        "# === BLOQUE 2: LECTURA Y ANÁLISIS DE DATOS ===\n",
        "\n",
        "# Leemos los archivos CSV\n",
        "ventas = pd.read_csv('ventas.csv')\n",
        "usuarios = pd.read_csv('usuarios.csv')\n",
        "\n",
        "# Mostramos los primeros registros de ambos archivos\n",
        "print(\"\\nDatos de Ventas:\")\n",
        "print(ventas.head())\n",
        "\n",
        "print(\"\\nDatos de Usuarios:\")\n",
        "print(usuarios.head())\n",
        "\n",
        "# Análisis de productos más vendidos\n",
        "productos_mas_vendidos = ventas.groupby('ProductoID')['CantidadVendida'].sum().sort_values(ascending=False)\n",
        "print(\"\\nProductos más vendidos:\")\n",
        "print(productos_mas_vendidos)\n",
        "\n",
        "# === BLOQUE 3: MACHINE LEARNING CON SCIKIT-LEARN ===\n",
        "\n",
        "# Importamos las librerías de Scikit-Learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Añadimos una columna de simulación de compra (0: no compra, 1: compra)\n",
        "usuarios['Compra'] = np.random.randint(0, 2, usuarios.shape[0])\n",
        "\n",
        "# Separamos las características (X) y la variable objetivo (y)\n",
        "X = usuarios[['TiempoEnSitio', 'PaginasVistas', 'ProductosVistos']]\n",
        "y = usuarios['Compra']\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# --- Modelo KNN (Clasificación) ---\n",
        "# Creamos y entrenamos un modelo de KNN\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Realizamos predicciones\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Calculamos la precisión del modelo\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nPrecisión del modelo KNN: {accuracy:.2f}\")\n",
        "\n",
        "# --- Modelo K-Means (Clustering) ---\n",
        "# Creamos y entrenamos un modelo de K-Means\n",
        "kmeans = KMeans(n_clusters=3, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Asignamos los usuarios a clusters\n",
        "usuarios['Cluster'] = kmeans.labels_\n",
        "\n",
        "print(\"\\nUsuarios agrupados en clusters:\")\n",
        "print(usuarios[['UsuarioID', 'Cluster']].head())\n",
        "\n",
        "# === BLOQUE 4: MACHINE LEARNING CON PYTORCH ===\n",
        "\n",
        "# Importamos las librerías de PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Definimos una red neuronal simple con PyTorch\n",
        "class RedNeuronal(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RedNeuronal, self).__init__()\n",
        "        self.fc1 = nn.Linear(3, 10)  # 3 entradas (tiempo, páginas, productos), 10 neuronas ocultas\n",
        "        self.fc2 = nn.Linear(10, 1)  # 1 salida (predicción de compra)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# Creamos el modelo de la red neuronal\n",
        "modelo_pytorch = RedNeuronal()\n",
        "\n",
        "# Definimos el optimizador y la función de pérdida\n",
        "criterio = nn.BCELoss()  # Binary Cross-Entropy Loss para clasificación binaria\n",
        "optimizador = optim.Adam(modelo_pytorch.parameters(), lr=0.001)\n",
        "\n",
        "# Convertimos los datos de entrada y las etiquetas a tensores\n",
        "X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Entrenamos el modelo de PyTorch durante 5 épocas\n",
        "for epoch in range(5):\n",
        "    # Forward pass\n",
        "    salida = modelo_pytorch(X_tensor)\n",
        "    perdida = criterio(salida, y_tensor)\n",
        "\n",
        "    # Backward pass y optimización\n",
        "    optimizador.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizador.step()\n",
        "\n",
        "    print(f\"Época {epoch+1}, Pérdida: {perdida.item():.4f}\")\n",
        "\n",
        "# === BLOQUE 5: DEEP LEARNING CON TENSORFLOW Y KERAS ===\n",
        "\n",
        "# Importamos TensorFlow y Keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Creamos una red neuronal profunda con Keras\n",
        "modelo_keras = Sequential([\n",
        "    Dense(10, input_shape=(3,), activation='relu'),  # Capa oculta con 10 neuronas\n",
        "    Dense(1, activation='sigmoid')                  # Capa de salida para clasificación binaria\n",
        "])\n",
        "\n",
        "# Compilamos el modelo\n",
        "modelo_keras.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Entrenamos el modelo con los datos de entrada\n",
        "modelo_keras.fit(X, y, epochs=5, batch_size=4)\n",
        "\n",
        "# Evaluamos el modelo\n",
        "perdida, precision = modelo_keras.evaluate(X, y)\n",
        "print(f\"\\nPrecisión del modelo con Keras: {precision:.2f}\")\n",
        "\n",
        "#extra\n",
        "# === BLOQUE EXTRA: VISUALIZACIÓN DE RESULTADOS ===\n",
        "\n",
        "# Importamos las librerías necesarias para la visualización\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuramos el estilo de los gráficos\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# --- 1. Distribución de los productos más vendidos ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=productos_mas_vendidos.index, y=productos_mas_vendidos.values, palette=\"viridis\")\n",
        "plt.title('Distribución de los Productos más Vendidos', fontsize=16)\n",
        "plt.xlabel('ProductoID', fontsize=12)\n",
        "plt.ylabel('Cantidad Vendida', fontsize=12)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n",
        "# --- 2. Gráfico de dispersión de usuarios agrupados en clusters ---\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x='PaginasVistas', y='ProductosVistos', hue='Cluster', data=usuarios, palette=\"deep\", s=100)\n",
        "plt.title('Distribución de Usuarios en Clusters', fontsize=16)\n",
        "plt.xlabel('Páginas Vistas', fontsize=12)\n",
        "plt.ylabel('Productos Vistos', fontsize=12)\n",
        "plt.show()\n",
        "\n",
        "# --- 3. Precisión del modelo KNN en gráfico de barras ---\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(['Precisión KNN'], [accuracy], color='skyblue')\n",
        "plt.title('Precisión del Modelo KNN', fontsize=16)\n",
        "plt.ylabel('Precisión', fontsize=12)\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n",
        "\n",
        "# --- 4. Pérdida del modelo PyTorch durante el entrenamiento ---\n",
        "# Almacenamos la pérdida del entrenamiento en PyTorch para cada época (modificar el bloque de entrenamiento)\n",
        "perdidas_pytorch = []\n",
        "\n",
        "# Modifica el bucle de entrenamiento en el bloque de PyTorch para guardar la pérdida\n",
        "for epoch in range(5):\n",
        "    salida = modelo_pytorch(X_tensor)\n",
        "    perdida = criterio(salida, y_tensor)\n",
        "    optimizador.zero_grad()\n",
        "    perdida.backward()\n",
        "    optimizador.step()\n",
        "    perdidas_pytorch.append(perdida.item())  # Almacenamos la pérdida\n",
        "\n",
        "# Graficamos la pérdida del modelo PyTorch\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(1, 6), perdidas_pytorch, marker='o', color='r', label='Pérdida PyTorch')\n",
        "plt.title('Evolución de la Pérdida en PyTorch', fontsize=16)\n",
        "plt.xlabel('Época', fontsize=12)\n",
        "plt.ylabel('Pérdida', fontsize=12)\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# --- 5. Precisión del modelo Keras ---\n",
        "# Ya tenemos el valor de precisión almacenado, lo graficamos en barras\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(['Precisión Keras'], [precision], color='lightgreen')\n",
        "plt.title('Precisión del Modelo con Keras', fontsize=16)\n",
        "plt.ylabel('Precisión', fontsize=12)\n",
        "plt.ylim(0, 1)\n",
        "plt.show()\n"
      ]
    }
  ]
}